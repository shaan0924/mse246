---
title: "Project Code"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r warning=FALSE, message=FALSE}
# Used Throughout
library(lubridate)
library(quantmod)
library(tidyverse)
library(data.table)
library(readxl) 
library(here) # Instead of setting WD with setwd, use the here() function for code transferability between devices

# For Logistic Model
library(leaps)
library(ROCR)
library(glmnet)

#Extra
library(devtools)
```

```{r}
# NOT WORKING - meant to provide us access to the Medical Expenditure Panel 
# Survey Household Component Dataset. But the package installation process isn't working 
# install_github("e-mitchell/meps_r_pkg/MEPS")
# library(MEPS)
```


# Data Import 
## ONLY RUN ON FIRST PASS
```{r warning=FALSE, message=FALSE}
# raw_data_xlxs <- read_xlsx(here('SBA Loan data .xlsx'))
# write.csv(raw_data_xlxs,here("SBA Loan data .csv"), row.names = FALSE)
```

## All Other Data
```{r warning=FALSE, message=FALSE}
raw_data <- read.csv("SBA Loan data .csv", header = TRUE)

#GDP Import
GDP = read.csv("GDP.csv")

#SP500 Import
SP500 = getSymbols("^GSPC",from = "1990-01-31",to = "2014-12-31", periodicity = 'monthly', auto.assign = FALSE)

#FedFunds Import
FEDFUNDS = read.csv("FEDFUNDS.csv")

#CPI Import (Consumer Price Index for All Urban Consumers: All Items in U.S. City Average)
CPI = read.csv("CPIAUCSL.csv")

#Unemployment
UnemploymentUSbyState = read.csv('StateUR.csv', header = TRUE)
```


# Data Exploration

## Gross Approval Frequencies and Annual Default Rate over time by Gross Approval Size

Slicing the Data into gross approval ranges
```{r}
temp = raw_data
temp = 
  transform(
    raw_data, 
    bin = 
      cut(
        GrossApproval, 
        breaks = c(0,100000, 250000, 500000, 750000, 1000000, 2000000, 10000000))
    )

raw_data$Size[temp$bin == "(0,1e+05]"] = "<$100k"
raw_data$Size[temp$bin == "(1e+05,2.5e+05]"] = "$100k-250K"
raw_data$Size[temp$bin == "(2.5e+05,5e+05]"] = "$250k-500k"
raw_data$Size[temp$bin == "(5e+05,7.5e+05]"] = "$500k-750k"
raw_data$Size[temp$bin == "(7.5e+05,1e+07]"] = "$750k+"
raw_data$Size[temp$bin == "(7.5e+05,1e+06]"] = "$750k-$1M"
raw_data$Size[temp$bin == "(1e+06,2e+0+6]"] = "$1M-$2M"
raw_data$Size[temp$bin == "(2e+06,1e+07]"] = "$2M+"
```

Visualizing the frequencies of loan volumes
```{r}
raw_data %>% 
  drop_na(Size) %>% 
  group_by(Size) %>% 
  summarise("Volume" = sum(GrossApproval)) %>% 
  ggplot(aes(x = Size, y = Volume, color = Size)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Total Loan Volume by Loan Size") + 
  xlab("Size") + 
  ylab("Total Loan Volume")
```

Visualizing the Annual Default Rate over time by Gross Approval Size
```{r}
raw_data %>% 
  group_by(ApprovalFiscalYear, Size) %>% 
  summarise("Annual Default Rate" = sum(LoanStatus == "CHGOFF")/sum(LoanStatus == "CHGOFF" | LoanStatus == "PIF")) %>% 
  mutate(Size = factor(Size, levels = c("<$100K", "$100k-250K", "$250k-500k", "$500k-750k", "$750k+", "$750k-$1M", "$1M-$2M", "$2M+"))) %>% 
  drop_na(Size) %>% 
  ggplot(
    aes(
      x = ApprovalFiscalYear, 
      y = `Annual Default Rate`, 
      group = Size, color = Size)
    ) + 
  geom_point() + 
  geom_line() + 
  ggtitle("Approval Year vs. Annual Default Rate by Gross Approval Size") + 
  xlab("Approval Year") + 
  ylab("Annual Default Rate") 
```

## Borrower Region vs. Annual Default Rate

Borrower Region Specification
```{r}
raw_data$BorrowerRegion[raw_data$BorrState == "ME"| raw_data$BorrState == "VT"| raw_data$BorrState == "NH"|raw_data$BorrState == "MA"| raw_data$BorrState == "RI"| raw_data$BorrState == "NY"| raw_data$BorrState == "CT"| raw_data$BorrState == "NJ"|raw_data$BorrState == "PA"] = "Northeast"

raw_data$BorrowerRegion[raw_data$BorrState == "ND"| raw_data$BorrState == "SD"| raw_data$BorrState == "NE"|raw_data$BorrState == "KS"| raw_data$BorrState == "MN"| raw_data$BorrState == "IA"| raw_data$BorrState == "MO"| raw_data$BorrState == "WI" | raw_data$BorrState == "IL"| raw_data$BorrState == "IN"| raw_data$BorrState == "MI" | raw_data$BorrState == "OH"] = "Midwest"

raw_data$BorrowerRegion[raw_data$BorrState == "TX"| raw_data$BorrState == "OK"| raw_data$BorrState == "AR"|raw_data$BorrState == "LA"| raw_data$BorrState == "MS"| raw_data$BorrState == "AL"| raw_data$BorrState == "TN"| raw_data$BorrState == "KY"| raw_data$BorrState == "WV"| raw_data$BorrState == "VA"|raw_data$BorrState == "MD"| raw_data$BorrState == "DC"| raw_data$BorrState == "DE"| raw_data$BorrState == "NC"| raw_data$BorrState == "SC"| raw_data$BorrState == "GA" | raw_data$BorrState == "FL" | raw_data$BorrState == "PR" | raw_data$BorrState == "VI"] = "South"

raw_data$BorrowerRegion[raw_data$BorrState == "WA"| raw_data$BorrState == "OR"| raw_data$BorrState == "CA"|raw_data$BorrState == "NV"| raw_data$BorrState == "ID"| raw_data$BorrState == "MT"| raw_data$BorrState == "UT"| raw_data$BorrState == "WY"|raw_data$BorrState == "CO"| raw_data$BorrState == "NM"| raw_data$BorrState == "AZ"| raw_data$BorrState == "AK"| raw_data$BorrState == "HI" | raw_data$BorrState == "GU"] = "West"
```

Visualizing the Annual Default Rate over time by Borrower Region
```{r}
raw_data %>% 
  drop_na(BorrowerRegion) %>% 
  group_by(BorrowerRegion) %>% 
  summarise("Volume" = sum(GrossApproval)) %>% 
  ggplot(aes(x = BorrowerRegion, y = Volume, color = BorrowerRegion)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Total Loan Volume by Borrower Region") + 
  xlab("Borrower Region") + 
  ylab("Total Loan Volume")

raw_data %>% 
  drop_na(BorrowerRegion) %>%  
  group_by(ApprovalFiscalYear, BorrowerRegion) %>% 
  summarise("Annual Default Rate" = sum(LoanStatus == "CHGOFF")/sum(LoanStatus == "CHGOFF" | LoanStatus == "PIF")) %>% 
  ggplot(
    aes(
      x = ApprovalFiscalYear, 
      y = `Annual Default Rate`, 
      group = BorrowerRegion, 
      color = BorrowerRegion)
    ) + 
  geom_point() + 
  geom_line() + 
  ggtitle("Approval Year vs. Annual Default Rate by Borrower Region") + 
  xlab("Approval Year") + 
  ylab("Annual Default Rate")
```

## Project Region vs. Annual Default Rate

Project Region Specification
```{r}
raw_data$ProjectRegion[raw_data$ProjectState == "ME"| raw_data$ProjectState == "VT"| raw_data$ProjectState == "NH"|raw_data$ProjectState == "MA"| raw_data$ProjectState == "RI"| raw_data$ProjectState == "NY"| raw_data$ProjectState == "CT"| raw_data$ProjectState == "NJ"|raw_data$ProjectState == "PA"] = "Northeast"

raw_data$ProjectRegion[raw_data$ProjectState == "ND"| raw_data$ProjectState == "SD"| raw_data$ProjectState == "NE"|raw_data$ProjectState == "KS"| raw_data$ProjectState == "MN"| raw_data$ProjectState == "IA"| raw_data$ProjectState == "MO"| raw_data$ProjectState == "WI" | raw_data$ProjectState == "IL"| raw_data$ProjectState == "IN"| raw_data$ProjectState == "MI" | raw_data$ProjectState == "OH"] = "Midwest"

raw_data$ProjectRegion[raw_data$ProjectState == "TX"| raw_data$ProjectState == "OK"| raw_data$ProjectState == "AR"|raw_data$ProjectState == "LA"| raw_data$ProjectState == "MS"| raw_data$ProjectState == "AL"| raw_data$ProjectState == "TN"| raw_data$ProjectState == "KY"| raw_data$ProjectState == "WV"| raw_data$ProjectState == "VA"|raw_data$ProjectState == "MD"| raw_data$ProjectState == "DC"| raw_data$ProjectState == "DE"| raw_data$ProjectState == "NC"| raw_data$ProjectState == "SC"| raw_data$ProjectState == "GA" | raw_data$ProjectState == "FL" | raw_data$ProjectState == "PR" | raw_data$ProjectState == "VI"] = "South"

raw_data$ProjectRegion[raw_data$ProjectState == "WA"| raw_data$ProjectState == "OR"| raw_data$ProjectState == "CA"|raw_data$ProjectState == "NV"| raw_data$ProjectState == "ID"| raw_data$ProjectState == "MT"| raw_data$ProjectState == "UT"| raw_data$ProjectState == "WY"|raw_data$ProjectState == "CO"| raw_data$ProjectState == "NM"| raw_data$ProjectState == "AZ"| raw_data$ProjectState == "AK"| raw_data$ProjectState == "HI" | raw_data$ProjectState == "GU"] = "West"
```

Loan Volume by Project Region
```{r}
raw_data %>% 
  drop_na(ProjectRegion) %>% 
  group_by(ProjectRegion) %>% 
  summarise("Volume" = sum(GrossApproval)) %>% 
  ggplot(aes(x=ProjectRegion, y = Volume, color = ProjectRegion)) + 
  geom_bar(stat="identity") + 
  ggtitle("Total Loan Volume by Project Region") + 
  xlab("Project Region") + 
  ylab("Total Loan Volume")
```

Visualizing the Annual Default Rate by Approval Year in each Project Region
```{r}
raw_data %>% 
  drop_na(ProjectRegion) %>%  
  group_by(ApprovalFiscalYear, ProjectRegion) %>% 
  summarise("Annual Default Rate" = sum(LoanStatus == "CHGOFF")/sum(LoanStatus == "CHGOFF" | LoanStatus == "PIF")) %>% 
  ggplot(
    aes(
      x = ApprovalFiscalYear,
      y = `Annual Default Rate`, 
      group = ProjectRegion, 
      color = ProjectRegion)
    ) + 
  geom_point() + 
  geom_line() + 
  ggtitle("Approval Year vs. Annual Default Rate by Project Region") + 
  xlab("Approval Year") + 
  ylab("Annual Default Rate")
```

## Business Type vs. Annual Default Rate

Loan Volume by Business Type
```{r}
raw_data[!(raw_data$BusinessType == ""), ] %>% 
  drop_na(BusinessType) %>% 
  group_by(BusinessType) %>% 
  summarise("Volume" = sum(GrossApproval)) %>% 
  ggplot(aes(x = BusinessType, y = Volume, color = BusinessType)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Total Loan Volume by Business Type") + 
  xlab("Business Type") + 
  ylab("Total Loan Volume")
```

Annual Default Rate per Approval Year by Business Type
```{r}
raw_data[!(raw_data$BusinessType == ""), ] %>% 
  group_by(ApprovalFiscalYear, BusinessType) %>% 
  summarise("Annual Default Rate" = sum(LoanStatus == "CHGOFF")/sum(LoanStatus == "CHGOFF" | LoanStatus == "PIF")) %>% 
  ggplot(
    aes(
      x = ApprovalFiscalYear, 
      y = `Annual Default Rate`, 
      group = BusinessType, 
      color = BusinessType)
    ) + 
  geom_point() + 
  geom_line() + 
  ggtitle("Approval Year vs. Annual Default Rate by Business Type") + 
  xlab("Approval Year") + 
  ylab("Annual Default Rate")
```

## NAICS vs. Annual Default Rate
Annual Default Rate per Approval Year by NAICS Code (Subset 1)
```{r}
temp = raw_data
temp$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "11"] = "Agriculture"
temp$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "21"] = "Mining & Oil"
temp$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "22"] = "Utilities"
temp$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "23"] = "Construction"
temp$NAICS_Sector[substring(raw_data$NaicsCode, 1, 1) == "3"] = "Manufacturing"
temp$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "42"] = "Wholesale Trade"
temp$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "44" | substring(raw_data$NaicsCode, 1, 2) == "45"] = "Retail Trade"
temp$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "48" | substring(raw_data$NaicsCode, 1, 2) == "49"] = "Transportation & Warehousing"
temp$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "51"] = "Information"
temp$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "52"] = "Finance & Insurance"

temp %>% 
  drop_na(NAICS_Sector) %>% 
  group_by(ApprovalFiscalYear, NAICS_Sector) %>% 
  summarise(
    "Annual Default Rate" = sum(LoanStatus == "CHGOFF")/sum(LoanStatus == "CHGOFF" | LoanStatus == "PIF")
  ) %>% 
  ggplot(
  aes(
    x = ApprovalFiscalYear, 
    y = `Annual Default Rate`, 
    group = NAICS_Sector, color = NAICS_Sector)
  ) + 
  geom_point() + 
  geom_line() + 
  ggtitle("Approval Year vs. Annual Default Rate by NAICS Sector (Subset 1)") + 
  xlab("Approval Year") + 
  ylab("Annual Default Rate")
```

Annual Default Rate per Approval Year by NAICS Code (Subset 2)
```{r}
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "53"] = "Real Estate & Leasing"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "54"] = "Professional Services"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "55"] = "Management Services"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "56"] = "Administrative and Waste Management Services"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "61"] = "Educational Services"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "62"] = "Health Care"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "71"] = "Arts & Entertainment"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "72"] = "Accommodation and Food Services"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "81"] = "Other Services"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "92"] = "Public Administration"

raw_data %>% 
  drop_na(NAICS_Sector) %>%  
  group_by(ApprovalFiscalYear, NAICS_Sector) %>% 
  summarise(
    "Annual Default Rate" = 
      sum(LoanStatus == "CHGOFF")/sum(LoanStatus == "CHGOFF" | LoanStatus == "PIF")
  ) %>% 
  ggplot(
    aes(x = ApprovalFiscalYear, 
        y = `Annual Default Rate`, 
        group = NAICS_Sector, 
        color = NAICS_Sector)
    ) + 
  geom_point() + 
  geom_line() + 
  ggtitle("Approval Year vs. Annual Default Rate by NAICS Sector (Subset 2)") + 
  xlab("Approval Year") + 
  ylab("Annual Default Rate")
```

Total Loan Volume by NAICS Code
```{r}
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "11"] = "Agriculture"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "21"] = "Mining & Oil"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "22"] = "Utilities"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "23"] = "Construction"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 1) == "3"] = "Manufacturing"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "42"] = "Wholesale Trade"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "44" | substring(raw_data$NaicsCode, 1, 2) == "45"] = "Retail Trade"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "48" | substring(raw_data$NaicsCode, 1, 2) == "49"] = "Transportation & Warehousing"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "51"] = "Information"
raw_data$NAICS_Sector[substring(raw_data$NaicsCode, 1, 2) == "52"] = "Finance & Insurance"

raw_data %>% 
  drop_na(NAICS_Sector) %>% 
  group_by(NAICS_Sector) %>% 
  summarise("Volume" = sum(GrossApproval)) %>% 
  ggplot(aes(x = NAICS_Sector, y=Volume, color = NAICS_Sector)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Total Loan Volume by NAICS Sector") + 
  xlab("NAICS Sector") + 
  ylab("Total Loan Volume")
```

Term Length vs. Annual Default Rate
```{r}
temp = raw_data
temp = transform(raw_data, bin = cut(TermInMonths, breaks= c(0, 119, 180, 240, 500)))
raw_data$TermLength[temp$bin == "(0,119]"] = "<120mths"
raw_data$TermLength[temp$bin == "(119,180]"] = "120-180mths"
raw_data$TermLength[temp$bin == "(180,240]"] = "181-240mths"
raw_data$TermLength[temp$bin == "(240,500]"] = "240mths+"

raw_data %>% 
  drop_na(TermLength) %>% 
  group_by(TermLength) %>% 
  summarise("Volume" = sum(GrossApproval)) %>% 
  ggplot(aes(x=TermLength, y=Volume, color = TermLength)) + 
  geom_bar(stat="identity") + 
  ggtitle("Total Loan Volume by Term Length") + 
  xlab("Term Length") + ylab("Total Loan Volume")

raw_data %>% 
  drop_na(TermLength) %>% 
  group_by(ApprovalFiscalYear, TermLength) %>% 
  summarise(
    "Annual Default Rate" = sum(LoanStatus == "CHGOFF")/sum(LoanStatus == "CHGOFF" | LoanStatus == "PIF")
  ) %>% 
  ggplot(
    aes(x=ApprovalFiscalYear, y= `Annual Default Rate`, group = TermLength, color = TermLength)) + 
  geom_point() + 
  geom_line() + 
  ggtitle("Approval Year vs. Annual Default Rate by Term Length") + 
  xlab("Approval Year") + 
  ylab("Annual Default Rate") 
```


# Pre-Processing the Data for Modeling

Data Cleaning - Dealing with states that are absent in the data and states in which there are no borrowers
```{r}
raw_data1 <- raw_data

raw_data1 %>% 
  select(ApprovalDate) %>% 
  mutate(date2 = as.Date(ApprovalDate, "%m/%d/%y"))
  
raw_data = raw_data[!(raw_data$LoanStatus=="CANCLD" | raw_data$LoanStatus=="EXEMPT"),]
#15 occurances of different states or NA thus delete those loans

unidentified.states = unique(raw_data$ProjectState[!(raw_data$ProjectState %in% unique(UnemploymentUSbyState$State))]) #States not in raw_data$ProjectState
raw_data = raw_data[!(raw_data$ProjectState %in% unidentified.states),] #remove those unidentified states from raw_data

#States not in raw_data$BorrState; aka, states in which there are no borrowers
unidentified.states.Borr = unique(raw_data$BorrState[!(raw_data$BorrState %in% unique(UnemploymentUSbyState$State))]) 

temp.data <- 
  raw_data %>% 
  mutate(
    ApprovalDate = as.Date(ApprovalDate),
    month.bin = cut(ApprovalDate, breaks = "month")
  )
```

## Addition of Unemployment Statistics at the State Level by Month 
```{r}
tempUR = rename(UnemploymentUSbyState, month.bin = DATE, ProjectState = State, URinProjectState = UR)
temp = merge(x=temp.data,y=tempUR,by=c("ProjectState","month.bin"))

tempUR.Borr = rename(UnemploymentUSbyState, month.bin = DATE, BorrState = State, URinBorrState = UR)
temp = merge(x=temp,y=tempUR.Borr,by=c("BorrState","month.bin"))
```

## Addition of GDP by Quarter
```{r}
tempGDP <- 
  transmute(GDP, month.bin = DATE, GDP = GDP) %>% 
  mutate(
    quarter.bin =
      case_when(
        as.numeric(substring(month.bin, 6, 7)) < 10 & as.numeric(substring(month.bin, 6, 7)) >= 7  ~ paste("Q3", substring(month.bin, 0, 4)),
        as.numeric(substring(month.bin, 6, 7)) < 7 & as.numeric(substring(month.bin, 6, 7)) >= 4   ~ paste("Q2", substring(month.bin, 0, 4)),
        as.numeric(substring(month.bin, 6, 7)) < 4                                                 ~ paste("Q1", substring(month.bin, 0, 4)),
        TRUE                                                                                       ~ paste("Q4", substring(month.bin, 0, 4)),
      )
  )

temp <- 
  temp %>% 
  mutate(
    quarter.bin =
      case_when(
        as.numeric(substring(ApprovalDate, 6, 7)) < 10 & as.numeric(substring(ApprovalDate, 6, 7)) >= 7  ~ paste("Q3", substring(ApprovalDate, 0, 4)),
        as.numeric(substring(ApprovalDate, 6, 7)) < 7 & as.numeric(substring(ApprovalDate, 6, 7)) >= 4   ~ paste("Q2", substring(ApprovalDate, 0, 4)),
        as.numeric(substring(ApprovalDate, 6, 7)) < 4                                                    ~ paste("Q1", substring(ApprovalDate, 0, 4)),
        TRUE                                                                                             ~ paste("Q4", substring(ApprovalDate, 0, 4)),
      )
  ) %>% 
  merge(y = tempGDP,by="quarter.bin") %>% 
  subset(select = -quarter.bin) %>% 
  subset(select = -month.bin.y) %>% 
  rename("month.bin" = month.bin.x)
```

## Addition of S&P 500 Data by Month
```{r}
tempSP500 = as.data.frame(SP500)
tempSP500$month.bin = rownames(tempSP500)
tempSP500 = transmute(tempSP500,  month.bin = rownames(tempSP500), GSPC.price= GSPC.Adjusted)
temp = merge(x = temp, y = tempSP500,by = "month.bin")
```

## Addition of Fed Funds by Month
```{r}
tempFedFunds = transmute(FEDFUNDS, month.bin = DATE, FedFunds = FEDFUNDS)
temp = merge(x=temp,y=tempFedFunds,by="month.bin")
```


## Addition of CPI by Month
```{r}
tempCPI = transmute(CPI, month.bin = DATE, CPI = CPIAUCSL)
temp = merge(x = temp, y = tempCPI,by = "month.bin")
raw_data = subset(temp, select = -month.bin)
```

## Addition of a Binary Term for Loans whose term is evenly divisible by 12 - BinaryIntergerTerm
```{r}
raw_data$BinaryIntergerTerm[raw_data$TermInMonths %% 12 == 0] = 1
raw_data$BinaryIntergerTerm[raw_data$TermInMonths %% 12 != 0] = 0
```

## Addition of a Binary term for repeat borrowers - BinaryRepeatBorrower
```{r}
temp = duplicated(raw_data$BorrName)
raw_data$BinaryRepeatBorrower[temp == TRUE] = 1 
raw_data$BinaryRepeatBorrower[temp == FALSE] = 0
```

## Addition of a Binary Term for Loans that have accepted Third Party Dollars - BinaryThirdPartyDollars
```{r}
#Not sure what to do with the NAs here. I'll keep them in for now
raw_data <- 
  raw_data %>% 
  mutate(
    BinaryThirdPartyDollars = 
      case_when(ThirdPartyDollars ~ 1, !ThirdPartyDollars ~ 0, TRUE ~ NA)
  )
```

## Addition of a Binary Term for Loans in which the Bank's State Matches the Borrower's State - BinaryBankStEqualBorrowerSt
```{r}
raw_data$BinaryBankStEqualBorrowerSt[as.character(raw_data$BorrState) == as.character(raw_data$CDC_State)] = 1
raw_data$BinaryBankStEqualBorrowerSt[as.character(raw_data$BorrState) != as.character(raw_data$CDC_State)] = 0
```

##BinaryProjectStEqualBorrowerSt
```{r}
# QUESTION: what does this do??
raw_data$BinaryProjectStEqualBorrowerSt[as.character(raw_data$BorrState) == as.character(raw_data$ProjectState)] = 1
raw_data$BinaryProjectStEqualBorrowerSt[as.character(raw_data$BorrState) != as.character(raw_data$ProjectState)] = 0
```

## Modifying Key Continous Variables to Log form: "LogGrossApproval", "TermInMonths", "LogGDP", "LogSP500", "LogFedFunds", "LogCPI", "URinProjectState", "URinBorrState" (NOTE: "LogThirdPartyDollars" has been removed. Not continuous - logical variable. Created BinaryThirdPartyDollars instead)
```{r}
raw_data$LogGrossApproval = log(raw_data$GrossApproval)
raw_data$LogGDP = log(raw_data$GDP)
raw_data$LogSP500 = log(raw_data$GSPC.price)
raw_data$LogFedFunds = log(raw_data$FedFunds)
raw_data$LogCPI = log(raw_data$CPI)
```

## Stitching Together Model Data and Adding Binary Default Variable: "BusinessType", "NAICS_Sector", "DeliveryMethod", "BinaryIntergerTerm", "BinaryRepeatBorrower", "BinaryBankStEqualBorrowerSt", "BinaryProjectStEqualBorrowerSt", "ApprovalFiscalYear", "BorrowerRegion", "ProjectRegion", "BinaryThirdPartyDollars"

```{r}
modified_data = raw_data[c("LogGrossApproval", "BinaryThirdPartyDollars", "TermInMonths", "LogGDP", "LogSP500", "LogFedFunds", "LogCPI", "URinProjectState", "URinBorrState", "BusinessType", "NAICS_Sector", "DeliveryMethod", "BinaryIntergerTerm", "BinaryRepeatBorrower", "BinaryBankStEqualBorrowerSt", "BinaryProjectStEqualBorrowerSt", "ApprovalFiscalYear", "BorrowerRegion", "ProjectRegion", "BinaryThirdPartyDollars")]

modified_data$Default[raw_data$LoanStatus == "CHGOFF"] = 1
modified_data$Default[raw_data$LoanStatus != "CHGOFF"] = 0
```

## Normalization
```{r}
c = 0.1

modified_data <- 
  modified_data %>% 
  mutate(
    across(
      .cols = 
        c(
          LogGrossApproval, 
          TermInMonths,
          LogGDP,
          LogSP500,
          LogFedFunds,
          LogCPI,
          URinProjectState,
          URinBorrState
        ),
      .fns = ~ (. - mean(., na.rm = TRUE)) / (c + sd(., na.rm = TRUE))
    )
  )
```

## Dealing with Missing Values
### Continous Variables
```{r}
temp = modified_data[c("LogGrossApproval", "TermInMonths", "LogGDP", "LogSP500", "LogFedFunds", "LogCPI", "URinProjectState", "URinBorrState")]
temp[is.na(temp)] = 0
modified_data[c("LogGrossApproval", "TermInMonths", "LogGDP", "LogSP500", "LogFedFunds", "LogCPI", "URinProjectState", "URinBorrState")] = temp
```

### Discrete Variables
```{r}
temp = modified_data[c("BusinessType", "NAICS_Sector", "DeliveryMethod", "BinaryIntergerTerm", "BinaryRepeatBorrower", "BinaryBankStEqualBorrowerSt", "BinaryProjectStEqualBorrowerSt", "ApprovalFiscalYear", "BorrowerRegion", "ProjectRegion", "BinaryThirdPartyDollars")]
temp[is.na(temp)] = "Blank"
modified_data[c("BusinessType", "NAICS_Sector", "DeliveryMethod", "BinaryIntergerTerm", "BinaryRepeatBorrower", "BinaryBankStEqualBorrowerSt", "BinaryProjectStEqualBorrowerSt", "ApprovalFiscalYear", "BorrowerRegion", "ProjectRegion", "BinaryThirdPartyDollars")] = temp
```

## Data Paritioning
```{r}
train_size = round((nrow(modified_data)/10)*7, 0)
validation_size = round((nrow(modified_data)/10), 0)
test_size = nrow(modified_data) - train_size - validation_size

train_data = modified_data[0:train_size,]
validation_data = modified_data[(train_size+1):(train_size+validation_size),]
test_data = modified_data[(train_size+validation_size+1):nrow(modified_data),]
```

# Creating the Basic Logistic Model
## Training the Model

```{r}
log_model = glm(data = train_data, Default ~., family = binomial)
summary(log_model) 

#Training ROC AUC
log_model_train_prediction = predict(log_model, train_data, type = "response")
log_model_train_prediction = prediction(log_model_train_prediction, train_data$Default)
auc = unlist(slot(performance(log_model_train_prediction, 'auc'), 'y.values'))
auc
#0.7256392

#Test ROC AUC
log_model_test_prediction = predict(log_model, newdata = test_data, type="response")
temp = test_data$Default[!is.na(log_model_test_prediction)]
log_model_test_prediction = log_model_test_prediction[!is.na(log_model_test_prediction)]
log_model_test_prediction = prediction(log_model_test_prediction, temp)
auc = unlist(slot(performance(log_model_test_prediction, 'auc'), 'y.values'))
auc
#0.6053772

#Plotting ROCs
roc_train = performance(log_model_train_prediction,"tpr","fpr")
roc_test = performance(log_model_test_prediction,"tpr","fpr")
plot(roc_train, col = 'red', main = 'Basic Logistic Model Training ROC (red) vs. Testing ROC (blue)')
plot(roc_test, add = TRUE, col = 'blue')
abline(a = 0, b = 1) 
```

# Ridge and Lasso Logisitic Model

# Training

```{r}
x_train = model.matrix(Default ~., train_data)[, -1]
x_train = x_train[,order(colnames(x_train))]
y_train = train_data$Default

model_L1 = glmnet(x_train, y_train, alpha = 1, nlambda = 10, family="binomial")
model_L2 = glmnet(x_train, y_train, alpha = 0, nlambda = 10, family="binomial")

x_validation = model.matrix(Default ~., validation_data)[, -1]
x_validation = x_validation[,order(colnames(x_validation))]

prediction_L1_train = predict(model_L1, newx = x_train, type = "response")
prediction_L2_train = predict(model_L2, newx = x_train, type = "response")
prediction_L1_validation = predict(model_L1, newx = x_validation, type = "response")
prediction_L2_validation = predict(model_L2, newx = x_validation, type = "response")
```

#Validation: Tuning Lambda Hyperparameter
AUC_L1_train = vector()
AUC_L2_train = vector()
AUC_L1_validation = vector()
AUC_L2_validation = vector()
for(i in 1:10){
  AUC_L1_train = append(AUC_L1_train, unlist(slot(performance(prediction(prediction_L1_train[,i], train_data$Default), 'auc'), 'y.values')))
  AUC_L2_train = append(AUC_L2_train, unlist(slot(performance(prediction(prediction_L2_train[,i], train_data$Default), 'auc'), 'y.values')))
  AUC_L1_validation = append(AUC_L1_validation, unlist(slot(performance(prediction(prediction_L1_validation[,i], validation_data$Default), 'auc'), 'y.values')))
  AUC_L2_validation = append(AUC_L2_validation,  unlist(slot(performance(prediction(prediction_L2_validation[,i], validation_data$Default), 'auc'), 'y.values')))
}

#Best L1 Hyperparameter
best_L1_lambda_index = which.max(AUC_L1_validation)
best_L1_lambda = model_L1$lambda[best_L1_lambda_index]
best_L1_AUC = max(AUC_L1_validation)
best_L1_AUC
#0.6699623
best_model_L1_coef = as.matrix(coef(model_L1, s= model_L1$lambda[best_L1_lambda_index]))

#Best L2 Hyperparameter
best_L2_lambda_index = which.max(AUC_L2_validation)
best_L2_lambda = model_L2$lambda[best_L2_lambda_index]
best_L2_AUC = max(AUC_L2_validation)
best_L2_AUC
#0.6719302
best_model_L2_coef = as.matrix(coef(model_L2, s= model_L2$lambda[best_L2_lambda_index]))

#Plotting best L1 & l2 coefficients
best_L1_model_coeff_plot = qplot(y= best_model_L1_coef[,1])
best_L1_model_coeff_plot + labs(title = "L1 Logistic Model Coeffcients", x= "Covariates", y= "Coeffcient Value")
best_L2_model_coeff_plot = qplot(y= best_model_L2_coef[,1])
best_L2_model_coeff_plot + labs(title = "L2 Logistic Model Coeffcients", x= "Covariates", y= "Coeffcient Value")

#Testing: best L2 model
x_test = model.matrix(Default ~., test_data)[, -1]
x_test = x_test[,order(colnames(x_test))]

prediction_L2_test = predict(model_L2, newx = x_test, s = best_L2_lambda,  type = "response")
prediction_L2_test = prediction(prediction_L2_test, test_data$Default)
auc = unlist(slot(performance(prediction_L2_test, 'auc'), 'y.values'))
auc
#0.5648184

#Plotting ROCs
roc_train = performance(prediction(prediction_L2_train[,best_L2_lambda_index], train_data$Default),"tpr","fpr")
roc_validation = performance(prediction(prediction_L2_validation[,best_L2_lambda_index], validation_data$Default),"tpr","fpr")
roc_test = performance(prediction_L2_test,"tpr","fpr")
plot(roc_train, col = 'red', main = 'L2 Logistic Model Training ROC (red) vs. Validation ROC (green) vs. Testing ROC (blue)')
plot(roc_validation, add = TRUE, col = 'green')
plot(roc_test, add = TRUE, col = 'blue')
abline(a = 0, b = 1) 

#################
#Data Paritioning
train_size = round((nrow(modified_data)/10)*7, 0)
validation_size = round((nrow(modified_data)/10), 0)
test_size = nrow(modified_data) - train_size - validation_size

train_data = modified_data[0:train_size,]
validation_data = modified_data[(train_size+1):(train_size+validation_size),]
test_data = modified_data[(train_size+validation_size+1):nrow(modified_data),]

#Setup
set.seed(1)
softplus = function(x) {log(1 + exp(x))}
sigmoid = function(x) {1/(1+ exp(-x))}
swish = function(x) {x*sigmoid(x)}

#Training: Default hidden layers c(4,2) & sigmoid & rep = 3
train_data_2 = train_data[sample(nrow(train_data), 5000), ]
nn = neuralnet(Default ~., data = train_data_2, hidden= c(4,2), rep = 3, act.fct = sigmoid, linear.output = FALSE)

plot(nn)
nn_train_prediction = compute(nn,train_data)
nn_train_prediction = as.vector(nn_train_prediction$net.result)
nn_train_prediction = prediction(nn_train_prediction, train_data$Default)
auc = unlist(slot(performance(nn_train_prediction, 'auc'), 'y.values'))
auc
#0.6615994

#Validation: Tuning architecture (Hidden Layer Count, Hidden Variables, act. fun)
act_functions = c('logistic', 'tanh', softplus, sigmoid, swish)
hidden_variables = c(2, 4, 8, 16, 32)
hidden_layers = c(1, 2, 3, 4, 5)

#Validation: Act. Function with Default c(4,2) for hidden layer
AUC_Act_Fn = vector()
for(i in 1:5){
  nn = neuralnet(Default ~., data = train_data_2, hidden= c(4,2), act.fct = act_functions[i], linear.output = FALSE)
  nn_validation_prediction = compute(nn,validation_data)
  nn_validation_prediction = as.vector(nn_validation_prediction$net.result)
  nn_validation_prediction = prediction(nn_validation_prediction, validation_data$Default)
  AUC_Act_Fn = append(AUC_Act_Fn, unlist(slot(performance(nn_validation_prediction, 'auc'), 'y.values')))
}

best_Act_Fn_index = which.max(AUC_Act_Fn)
best_Act_Fn_AUC = max(AUC_Act_Fn)
best_Act_Fn_AUC
#...

#Validation: Hidden Variables  with Default 2 hidden layers & best Act Fn
AUC_Hidden_Variables = vector()
for(i in 1:5){
  nn = neuralnet(Default ~., data = train_data_2, hidden= c(AUC_Hidden_Variables[i],AUC_Hidden_Variables[i]/2), act.fct = act_functions[best_Act_Fn_index], linear.output = FALSE)
  nn_validation_prediction = compute(nn,validation_data)
  nn_validation_prediction = as.vector(nn_validation_prediction$net.result)
  nn_validation_prediction = prediction(nn_validation_prediction, validation_data$Default)
  AUC_Hidden_Variables = append(AUC_Hidden_Variables, unlist(slot(performance(nn_validation_prediction, 'auc'), 'y.values')))
}

best_Hidden_Variables_index = which.max(AUC_Hidden_Variables)
best_Hidden_Variables_AUC = max(AUC_Hidden_Variables)
best_Hidden_Variables_AUC
#...

#Validation: Hidden Layers with best hidden variables & best Act Fn
#Need to manually build hidden layer structure given hidden variable output
AUC_Hidden_Layers = vector()
for(i in 1:5){
  nn = neuralnet(Default ~., data = train_data_2, hidden= c(AUC_Hidden_Variables[best_Hidden_Variables_index],AUC_Hidden_Variables[i]/2), act.fct = act_functions[best_Act_Fn_index], linear.output = FALSE)
  nn_validation_prediction = compute(nn,validation_data)
  nn_validation_prediction = as.vector(nn_validation_prediction$net.result)
  nn_validation_prediction = prediction(nn_validation_prediction, validation_data$Default)
  AUC_Hidden_Layers = append(AUC_Hidden_Layers, unlist(slot(performance(nn_validation_prediction, 'auc'), 'y.values')))
}

best_Hidden_Layers_index = which.max(AUC_Hidden_Layers)
best_Hidden_Layers_AUC = max(AUC_Hidden_Layers)
best_Hidden_Layers_AUC
#...
